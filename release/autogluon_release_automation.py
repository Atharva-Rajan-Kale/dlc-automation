"""
title : AutoGluon Release Images and Documentation Automation

description : Comprehensive two-phase automation system for updating release configuration files
and documentation. Phase 1 updates YAML release_images files with new AutoGluon
configurations and creates PR for review. Phase 2 reverts YAML changes, updates
available_images.md documentation with constructed image URLs, and creates combined
PR for final release. Handles both major and minor releases with intelligent version
shifting, ECR integration for image metadata extraction, and automated git workflows.
"""

import os
import re
import sys
import yaml
import logging
import subprocess
import shutil
import boto3
from pathlib import Path
from typing import Dict, Optional, Tuple
import subprocess
from datetime import datetime
sys.path.append(str(Path(__file__).parent))
from automation.common import BaseAutomation, ECRImageSelector
from testing.github_pr_automation import GitHubPRAutomation
from automation.automation_logger import LoggerMixin

class AutoGluonReleaseImagesAutomation(BaseAutomation,LoggerMixin):
    """
    Automation for updating release_images files and available_images.md with AutoGluon configuration
    """
    PRODUCTION_ACCOUNT_ID = '763104351884'
    DEFAULT_REGION = 'us-west-2'  # Updated to use us-west-2 as default
    
    def __init__(self, current_version: str, previous_version: str, fork_url: str, yaml_only: bool = False):
        super().__init__(current_version, previous_version, fork_url)
        self.training_file = self.repo_dir / "release_images_training.yml"
        self.inference_file = self.repo_dir / "release_images_inference.yml"
        self.available_images_file = self.repo_dir / "available_images.md"
        
        # Set branch name based on mode
        if yaml_only:
            branch_suffix = "release"
        else:
            branch_suffix = "update"
        
        self.branch_name = f"{current_version}-{branch_suffix}"
        
        self.pr_automation = GitHubPRAutomation(
            current_version=current_version,
            fork_url=fork_url,
            repo_dir=self.repo_dir
        )
        self.pr_automation.branch_name = self.branch_name
        self.original_training_content = None
        self.original_inference_content = None
        self.original_available_images_content = None
        self.setup_logging(current_version,custom_name="autogluon_release")

    def get_github_token(self) -> Optional[str]:
        """Get GitHub token from environment or GitHub CLI"""
        token = os.environ.get('GITHUB_TOKEN')
        if token:
            return token
        try:
            result = self.run_subprocess_with_logging(
                ["gh", "auth", "token"], 
                capture_output=True, 
                text=True, 
                check=True
            )
            return result.stdout.strip()
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.logger.warning("Could not get GitHub token from gh CLI")
            return None

    def configure_git_with_token(self, token: str) -> bool:
        """Configure Git with GitHub token for authentication"""
        try:
            self.run_subprocess_with_logging(
                ["git", "config", "user.name", "Atharva-Rajan-Kale"], 
                capture_output=True
            )
            self.run_subprocess_with_logging(
                ["git", "config", "user.email", "atharvakale912@gmail.com"], 
                capture_output=True
            )
            result = self.run_subprocess_with_logging(
                ["git", "remote", "get-url", "origin"], 
                capture_output=True, 
                text=True
            )
            current_url = result.stdout.strip()
            if "@github.com" in current_url and "https://" in current_url:
                self.logger.info("‚úÖ Git remote already configured with token")
                return True
            if current_url.startswith("https://github.com/"):
                authenticated_url = current_url.replace(
                    "https://github.com/", 
                    f"https://{token}@github.com/"
                )
                self.run_subprocess_with_logging(
                    ["git", "remote", "set-url", "origin", authenticated_url], 
                    check=True
                )
                self.logger.info("‚úÖ Configured git remote with GitHub token")
            else:
                self.logger.warning(f"‚ö†Ô∏è Unexpected remote URL format: {current_url}")
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to configure git with token: {e}")
            return False

    def setup_git_config(self):
        """Setup git configuration for CI environment"""
        try:
            token = self.get_github_token()
            if not token:
                self.logger.error("‚ùå No GitHub token available")
                return False
            if not self.configure_git_with_token(token):
                self.logger.error("‚ùå Failed to configure git with token")
                return False
            self.logger.info("‚úÖ Git configuration and authentication set")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to setup git config: {e}")
            return False

    def setup_repository(self) -> bool:
        """Clone repository from fork URL (master branch) and create/checkout release branch for pushing"""
        self.logger.info("üîß Setting up repository from fork...")
        original_dir = os.getcwd()
        try:
            self.workspace_dir.mkdir(exist_ok=True)
            os.chdir(self.workspace_dir)
            if Path("deep-learning-containers").exists():
                self.logger.info("Removing existing repository clone...")
                shutil.rmtree("deep-learning-containers")
            self.logger.info(f"Cloning from {self.fork_url} (master branch)")
            self.run_subprocess_with_logging([
                "git", "clone", self.fork_url, "deep-learning-containers"
            ], check=True)
            
            os.chdir("deep-learning-containers")
            if not self.setup_git_config():
                return False
            self.logger.info("üîß Adding upstream remote for clean branch creation...")
            self.run_subprocess_with_logging([
                "git", "remote", "add", "upstream", "https://github.com/aws/deep-learning-containers.git"
            ], check=True)
            self.logger.info("üîÑ Fetching upstream master for clean branch...")
            self.run_subprocess_with_logging([
                "git", "fetch", "upstream", "master"
            ], check=True)
            branch_name = self.branch_name
            self.logger.info(f"Creating clean release branch '{branch_name}' from upstream/master...")
            
            try:
                result = self.run_subprocess_with_logging([
                    "git", "branch", "--list", branch_name
                ], capture_output=True, text=True, check=False)
                
                if result.stdout.strip():
                    self.logger.info(f"Deleting existing local branch: {branch_name}")
                    self.run_subprocess_with_logging([
                        "git", "branch", "-D", branch_name
                    ], check=True)
                self.run_subprocess_with_logging([
                    "git", "checkout", "-b", branch_name, "upstream/master"
                ], check=True)
                self.logger.info(f"‚úÖ Created clean release branch: {branch_name} from upstream/master")
                self.logger.info(f"üìã This ensures PR will only show your changes, not fork history")
                
            except subprocess.CalledProcessError as e:
                self.logger.error(f"‚ùå Failed to create release branch: {e}")
                return False
            self.repo_dir = Path.cwd()
            self.logger.info(f"‚úÖ Repository setup complete: {self.repo_dir}")
            self.logger.info(f"üìã Workflow: Clean branch from upstream/master ‚Üí Working on {branch_name} ‚Üí Will push to fork")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Repository setup failed: {e}")
            return False
        finally:
            os.chdir(original_dir)

    def prompt_user(self, question: str) -> bool:
        """Prompt user with a yes/no question and repeat until valid answer"""
        while True:
            response = input(f"{question} (y/n): ").strip().lower()
            if response in ['y', 'yes']:
                return True
            elif response in ['n', 'no']:
                return False
            else:
                print("Please enter 'y' or 'n'")
                
    def wait_for_cr_completion(self):
        """Wait for CR process completion"""
        print("üîç Checking CR process completion status...")
        while True:
            if self.prompt_user("Is the CR process completed?"):
                print("‚úÖ CR process confirmed as completed. Proceeding...")
                break
            else:
                print("‚è≥ Waiting for CR process completion...")

    def run_yaml_only_automation(self):
        """Run only YAML file updates and PR creation"""
        try:
            print("üöÄ Starting AutoGluon YAML-Only Release Automation...")
            
            print("üîß Setting up repository from fork...")
            if not self.setup_repository():
                raise Exception("Failed to setup repository from fork")
            
            self.wait_for_cr_completion()
            
            print("üîç Extracting image information for YAML files...")
            print(f"üìã Using environment ACCOUNT_ID for beta repositories")
            image_info = self.get_latest_training_gpu_image()
            if not image_info:
                raise Exception("Failed to get training image information")
                
            print(f"üì¶ Image info extracted from {image_info['tag']}:")
            print(f"   OS Version: {image_info['os_version']}")
            print(f"   Python Versions: {image_info['python_versions']}")
            print(f"   CUDA Version: {image_info['cuda_version']}")
            
            self.backup_yaml_files()
            print("üìù Updating release_images files...")
            if not self.update_release_images_files(image_info):
                raise Exception("Failed to update release_images files")
                
            print("‚úÖ Release images files updated successfully")
            
            if not self.prompt_user("Commit and create PR with YAML changes?"):
                print("‚ùå Operation cancelled by user")
                return False
                
            commit_message = f"AutoGluon {self.current_version}: Add release images configuration"
            print(f"üîÑ Committing and pushing changes: {commit_message}")
            if not self.commit_and_push_yaml_changes(commit_message):
                raise Exception("Failed to commit and push YAML changes")
            print("‚úÖ Changes committed and pushed successfully")
                
            print("üöÄ Creating Pull Request for YAML changes...")
            self.logger.info(f"Using branch name: {self.pr_automation.branch_name}")
            original_dir = os.getcwd()
            try:
                os.chdir(self.repo_dir)
                self.logger.info("üîß Resetting remote URL for PR automation...")
                clean_url = self.fork_url
                self.run_subprocess_with_logging([
                    "git", "remote", "set-url", "origin", clean_url
                ], check=True)
                
                if not self.pr_automation.create_pull_request():
                    raise Exception("Failed to create Pull Request")
                print("‚úÖ Pull Request created successfully")
            finally:
                os.chdir(original_dir)
                
            print("‚úÖ YAML-Only AutoGluon Release Automation completed successfully!")
            print("üìã Summary:")
            print("   - Repository: Cloned from master and release branch created")
            print("   - YAML files: Updated and committed")
            print("   - PR created successfully")
            print("   - Ready for review and merge")
            print("\nüîÑ Next steps:")
            print("   1. Review and merge the YAML PR")
            print("   2. Run the script again WITHOUT --yaml-only flag for the second part")
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå YAML-only automation failed: {e}")
            print(f"‚ùå Error: {e}")
            return False

    def run_revert_and_available_images_automation(self):
        """Run revert YAML + update available_images.md + create single combined PR"""
        try:
            print("üöÄ Starting AutoGluon Revert and Available Images Automation...")
            
            print("üîß Setting up repository from fork...")
            if not self.setup_repository():
                raise Exception("Failed to setup repository from fork")
            
            print("üîç Extracting image information for available_images.md...")
            image_info = self.get_latest_training_gpu_image()
            if not image_info:
                raise Exception("Failed to get training image information")
                
            print(f"üì¶ Using image info from {image_info['tag']} for URL construction")
            
            self.backup_yaml_files()
            self.backup_available_images_file()
            
            print("üîÑ Reverting YAML changes...")
            if not self.revert_yaml_files():
                raise Exception("Failed to revert YAML files")
            print("‚úÖ YAML files reverted successfully")
            
            print("üìù Starting available_images.md update process...")
            print("üîß Constructing image URLs using specified pattern...")
            print(f"üìã Using production account ID: {self.PRODUCTION_ACCOUNT_ID}")
            print(f"üìã Using region: {os.environ.get('REGION', self.DEFAULT_REGION)}")
            
            constructed_images = self.construct_image_urls_by_type(image_info)
            training_images = constructed_images['training']
            inference_images = constructed_images['inference']
            
            if not training_images or not inference_images:
                raise Exception("Failed to construct sufficient image URLs")
                
            print(f"üì¶ Constructed training images: {list(training_images.keys()) if isinstance(training_images, dict) else type(training_images)}")
            print(f"üì¶ Constructed inference images: {list(inference_images.keys()) if isinstance(inference_images, dict) else type(inference_images)}")
            
            for img_type, img_data in training_images.items():
                self.logger.info(f"üì¶ Training {img_type} constructed URL: {img_data.get('image_uri', 'N/A')}")
            for img_type, img_data in inference_images.items():
                self.logger.info(f"üì¶ Inference {img_type} constructed URL: {img_data.get('image_uri', 'N/A')}")
            
            print("üìù Updating available_images.md with constructed image URLs...")
            if not self.update_available_images_md(training_images, inference_images):
                raise Exception("Failed to update available_images.md")
            print("‚úÖ available_images.md updated successfully with constructed image URLs")
            
            if not self.prompt_user("Commit and create PR with both YAML revert and available_images.md changes?"):
                print("‚ùå Operation cancelled by user")
                return False
                
            combined_commit_message = f"AutoGluon {self.current_version}: Revert release images config and update available images documentation"
            print(f"üîÑ Committing and pushing combined changes: {combined_commit_message}")
            if not self.commit_and_push_combined_changes(combined_commit_message):
                raise Exception("Failed to commit and push combined changes")
            print("‚úÖ Combined changes committed and pushed successfully")
                
            print("üöÄ Creating Pull Request for combined changes...")
            self.logger.info(f"Using branch name: {self.pr_automation.branch_name}")
            
            # Reset remote URL to clean version before PR automation to avoid token duplication
            original_dir = os.getcwd()
            try:
                os.chdir(self.repo_dir)
                self.logger.info("üîß Resetting remote URL for PR automation...")
                clean_url = self.fork_url
                self.run_subprocess_with_logging([
                    "git", "remote", "set-url", "origin", clean_url
                ], check=True)
                
                if not self.pr_automation.create_pull_request():
                    raise Exception("Failed to create Pull Request")
                print("‚úÖ Pull Request created successfully")
            finally:
                os.chdir(original_dir)
                
            print("‚úÖ Revert and Available Images Automation completed successfully!")
            print("üìã Summary:")
            print("   - Repository: Cloned from master and release branch created")
            print("   - YAML files: Reverted to original state")
            print("   - available_images.md: Updated with constructed image URLs")
            print("   - Single PR created with both changes")
            print("   - Ready for review and merge")
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Revert and available images automation failed: {e}")
            print(f"‚ùå Error: {e}")
            return False

    def commit_and_push_combined_changes(self, commit_message: str):
        """Commit and push both YAML revert and available_images.md changes in single commit"""
        try:
            original_dir = os.getcwd()
            os.chdir(self.repo_dir)
            
            self.run_subprocess_with_logging(['git', 'add', 'release_images_training.yml', 'release_images_inference.yml', 'available_images.md'], check=True)
            
            self.run_subprocess_with_logging(['git', 'commit', '-m', commit_message], check=True)
            
            # Use the instance variable
            self.run_subprocess_with_logging(['git', 'push', 'origin', self.branch_name], check=True)
            self.logger.info(f"‚úÖ Combined changes committed and pushed: {commit_message}")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to commit and push combined changes: {e}")
            return False
        finally:
            os.chdir(original_dir)

    def run_release_images_automation(self, yaml_only: bool = False):
        """Main automation workflow dispatcher"""
        if yaml_only:
            return self.run_yaml_only_automation()
        else:
            return self.run_revert_and_available_images_automation()

    def get_latest_autogluon_images_by_type(self, repo_name: str, account_id: str = None) -> Dict[str, Dict]:
        """Get the latest GPU and CPU images from autogluon repository"""
        if account_id is None:
            account_id = os.environ.get('ACCOUNT_ID')
        self.logger.info(f"üîç Getting latest GPU and CPU images from {repo_name} using account {account_id}...")
        region = os.environ.get('REGION', 'us-east-1')
        if not account_id:
            raise ValueError("ACCOUNT_ID environment variable not set and no account_id provided")
        ecr_client = boto3.client('ecr', region_name=region)
        try:
            response = ecr_client.describe_images(
                registryId=account_id,
                repositoryName=repo_name,
                maxResults=50
            )
            images = sorted(
                response['imageDetails'], 
                key=lambda x: x['imagePushedAt'], 
                reverse=True
            )
            self.logger.info(f"üì¶ Found {len(images)} total images in {repo_name}")
            latest_gpu = None
            latest_cpu = None
            for image in images:
                if 'imageTags' in image:
                    tag = image['imageTags'][0]
                    if not latest_gpu and '-gpu-' in tag:
                        image_info = self.parse_image_tag(tag, require_cuda=True)
                        if image_info:
                            image_uri = f"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:{tag}"
                            image_info['image_uri'] = image_uri
                            image_info['tag'] = tag
                            latest_gpu = image_info
                            self.logger.info(f"üì¶ Found latest GPU image: {tag}")
                    if not latest_cpu and '-cpu-' in tag:
                        image_info = self.parse_image_tag(tag, require_cuda=False)
                        if image_info:
                            image_uri = f"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:{tag}"
                            image_info['image_uri'] = image_uri
                            image_info['tag'] = tag
                            latest_cpu = image_info
                            self.logger.info(f"üì¶ Found latest CPU image: {tag}")
                    if latest_gpu and latest_cpu:
                        break
            result = {}
            if latest_gpu:
                result['gpu'] = latest_gpu
            if latest_cpu:
                result['cpu'] = latest_cpu
            self.logger.info(f"‚úÖ Found {len(result)} image types from {repo_name}")
            return result
        except Exception as e:
            self.logger.error(f"‚ùå Failed to get images from {repo_name}: {e}")
            return {}

    def construct_image_urls_by_type(self, reference_image_info: Dict) -> Dict[str, Dict]:
        """Construct image URLs for both training and inference, GPU and CPU using the specified pattern"""
        self.logger.info("üîß Constructing image URLs using specified pattern...")
        
        region = os.environ.get('REGION', self.DEFAULT_REGION)
        account_id = self.PRODUCTION_ACCOUNT_ID
        
        python_version = reference_image_info['python_versions'][0]
        cuda_version = reference_image_info['cuda_version']
        os_version = reference_image_info['os_version']
        
        self.logger.info(f"üìã Using extracted info - Python: {python_version}, CUDA: {cuda_version}, OS: {os_version}")
        
        constructed_images = {
            'training': {},
            'inference': {}
        }
        
        for job_type in ['training', 'inference']:
            # GPU image
            gpu_tag = f"{self.current_version}-gpu-{python_version}-{cuda_version}-{os_version}"
            gpu_uri = f"{account_id}.dkr.ecr.{region}.amazonaws.com/autogluon-{job_type}:{gpu_tag}"
            
            constructed_images[job_type]['gpu'] = {
                'image_uri': gpu_uri,
                'tag': gpu_tag,
                'python_versions': [python_version],
                'cuda_version': cuda_version,
                'os_version': os_version
            }
            
            # CPU image (no CUDA version)
            cpu_tag = f"{self.current_version}-cpu-{python_version}-{os_version}"
            cpu_uri = f"{account_id}.dkr.ecr.{region}.amazonaws.com/autogluon-{job_type}:{cpu_tag}"
            
            constructed_images[job_type]['cpu'] = {
                'image_uri': cpu_uri,
                'tag': cpu_tag,
                'python_versions': [python_version],
                'cuda_version': '',
                'os_version': os_version
            }
            
            self.logger.info(f"üì¶ Constructed {job_type} GPU URL: {gpu_uri}")
            self.logger.info(f"üì¶ Constructed {job_type} CPU URL: {cpu_uri}")
        
        return constructed_images
        
    def get_latest_autogluon_images(self, repo_name: str, count: int = 2, account_id: str = None, gpu_only: bool = False) -> list[Dict]:
        """Get the latest N images from any autogluon repository (beta or production) - Legacy method"""
        if account_id is None:
            account_id = os.environ.get('ACCOUNT_ID')
        self.logger.info(f"üîç Getting latest {count} images from {repo_name} using account {account_id}...")
        region = os.environ.get('REGION', 'us-east-1')
        if not account_id:
            raise ValueError("ACCOUNT_ID environment variable not set and no account_id provided")
        ecr_client = boto3.client('ecr', region_name=region)
        try:
            response = ecr_client.describe_images(
                registryId=account_id,
                repositoryName=repo_name,
                maxResults=50
            )
            images = sorted(
                response['imageDetails'], 
                key=lambda x: x['imagePushedAt'], 
                reverse=True
            )
            self.logger.info(f"üì¶ Found {len(images)} total images in {repo_name}")
            result_images = []
            for image in images:
                if 'imageTags' in image and len(result_images) < count:
                    tag = image['imageTags'][0]
                    if gpu_only and '-cpu-' in tag:
                        continue
                    require_cuda = '-gpu-' in tag
                    image_info = self.parse_image_tag(tag, require_cuda=require_cuda)
                    if image_info:
                        image_uri = f"{account_id}.dkr.ecr.{region}.amazonaws.com/{repo_name}:{tag}"
                        image_info['image_uri'] = image_uri
                        image_info['tag'] = tag
                        result_images.append(image_info)
                        self.logger.info(f"üì¶ Added image: {tag}")
            
            self.logger.info(f"‚úÖ Found {len(result_images)} valid images from {repo_name}")
            return result_images
        except Exception as e:
            self.logger.error(f"‚ùå Failed to get images from {repo_name}: {e}")
            return []
        
    def get_latest_training_gpu_image(self) -> Optional[Dict]:
        """Get the most recent training GPU image from beta-autogluon-training repository"""
        self.logger.info("üîç Getting the most recent training GPU image from beta repository...")
        images = self.get_latest_autogluon_images('beta-autogluon-training', 1, None, gpu_only=True)
        if images:
            self.logger.info(f"üì¶ Found most recent GPU training image: {images[0]['tag']}")
            return images[0]
        self.logger.warning("‚ö†Ô∏è No GPU training images found in beta repository")
        return None
    
    def convert_python_version(self, py_version: str) -> str:
        """Convert py311 to 3.11 format"""
        if py_version.startswith('py'):
            version_num = py_version[2:]
            if len(version_num) == 3:
                return f"{version_num[0]}.{version_num[1:]}"
            elif len(version_num) == 2:
                return f"{version_num[0]}.{version_num[1]}"
        return py_version
    
    def update_available_images_md(self, training_images: Dict[str, Dict], inference_images: Dict[str, Dict]) -> bool:
        """Update available_images.md with new AutoGluon version information using constructed URLs"""
        try:
            self.logger.info("üìù Updating available_images.md with constructed URLs...")
            if not self.available_images_file.exists():
                self.logger.error(f"‚ùå File not found: {self.available_images_file}")
                return False
            with open(self.available_images_file, 'r') as f:
                content = f.read()
            self.logger.info(f"üìã Original file size: {len(content)} characters")
            
            if not isinstance(training_images, dict) or not isinstance(inference_images, dict):
                self.logger.error(f"‚ùå Expected dictionaries but got: training_images={type(training_images)}, inference_images={type(inference_images)}")
                return False
            
            if 'gpu' not in training_images or 'gpu' not in inference_images:
                self.logger.error("‚ùå GPU images not found in training or inference images")
                return False
            
            if self.is_major_release:
                self.logger.info("üîÑ Major version update detected - moving current to Prior sections")
                content = self.move_current_to_prior(content)
            
            content = self.update_main_sections_with_constructed_urls(content, training_images, inference_images)
            self.logger.info(f"üìã Updated file size: {len(content)} characters")
            
            with open(self.available_images_file, 'w') as f:
                f.write(content)
            self.logger.info("‚úÖ available_images.md updated successfully with constructed URLs")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to update available_images.md: {e}")
            import traceback
            self.logger.error(f"Full traceback: {traceback.format_exc()}")
            return False
    
    def move_current_to_prior(self, content: str) -> str:
        """Move current AutoGluon sections to Prior sections for major version updates"""
        lines = content.split('\n')
        new_lines = []
        
        self.logger.info("üîÑ Moving current AutoGluon sections to Prior sections")
        
        # Extract current training section
        current_training_section = self.extract_current_section(lines, "AutoGluon Training Containers")
        current_inference_section = self.extract_current_section(lines, "AutoGluon Inference Containers")
        
        self.logger.info(f"üìã Extracted training section: {len(current_training_section)} lines")
        self.logger.info(f"üìã Extracted inference section: {len(current_inference_section)} lines")
        
        i = 0
        while i < len(lines):
            line = lines[i]
            if "Prior AutoGluon Training Containers" in line:
                self.logger.info("üìù Found Prior AutoGluon Training Containers section")
                if current_training_section:
                    new_lines.extend(current_training_section)
                    new_lines.append("") 
                new_lines.append(line)
                i += 1
                continue
            elif "Prior AutoGluon Inference Containers" in line:
                self.logger.info("üìù Found Prior AutoGluon Inference Containers section")
                if current_inference_section:
                    new_lines.extend(current_inference_section)
                    new_lines.append("") 
                new_lines.append(line)
                i += 1
                continue
            elif i == len(lines) - 1:
                new_lines.append(line)
                if current_training_section:
                    new_lines.append("")
                    new_lines.extend(current_training_section)
                if current_inference_section:
                    new_lines.append("")
                    new_lines.extend(current_inference_section)
                i += 1
                continue
                
            else:
                new_lines.append(line)
                i += 1
        
        self.logger.info("‚úÖ Current sections moved to Prior sections")
        return '\n'.join(new_lines)
    
    def extract_section(self, lines: list[str], section_name: str) -> list[str]:
        """Extract a table section from the markdown"""
        section_lines = []
        i = 0
        found_section = False
        while i < len(lines):
            line = lines[i]
            if section_name in line:
                found_section = True
                section_lines.append(line)
                i += 1
                while i < len(lines):
                    next_line = lines[i]
                    if (next_line.startswith("AutoGluon") and "Containers" in next_line and 
                        section_name not in next_line):
                        break
                    if next_line.startswith("Prior AutoGluon") or next_line.startswith("(--------"):
                        break
                    section_lines.append(next_line)
                    i += 1
                break
            i += 1
        return section_lines if found_section else []
    
    def update_main_sections_with_constructed_urls(self, content: str, training_images: Dict[str, Dict], inference_images: Dict[str, Dict]) -> str:
        """Update the main AutoGluon sections with constructed image URLs"""
        lines = content.split('\n')
        new_lines = []
        self.logger.info("üîç Updating main sections with constructed image URLs")
        
        autogluon_lines = []
        for i, line in enumerate(lines):
            if "AutoGluon" in line and "Containers" in line:
                autogluon_lines.append(f"Line {i}: {line.strip()}")
        if autogluon_lines:
            self.logger.info(f"üìã Found {len(autogluon_lines)} AutoGluon container sections:")
            for line in autogluon_lines:
                self.logger.info(f"   {line}")
        
        training_section_found = False
        inference_section_found = False
        i = 0
        while i < len(lines):
            line = lines[i]
            if line.strip() == "AutoGluon Training Containers":
                self.logger.info(f"üìù Found AutoGluon Training Containers section at line {i}")
                training_section_found = True
                new_lines.append(line)
                new_lines.append("===============================")
                new_lines.append("")  
                new_lines.append("| Framework       | AutoGluon Version  | Job Type | CPU/GPU | Python Version Options | Example URL                                                                                      |")
                new_lines.append("|-----------------|--------------------|----------|---------|------------------------|--------------------------------------------------------------------------------------------------|")
                
                if 'gpu' in training_images:
                    gpu_row = self.create_table_row_with_constructed_url(training_images['gpu'], "training", "GPU")
                    new_lines.append(gpu_row)
                if 'cpu' in training_images:
                    cpu_row = self.create_table_row_with_constructed_url(training_images['cpu'], "training", "CPU")
                    new_lines.append(cpu_row)
                
                i += 1
                while i < len(lines):
                    next_line = lines[i].strip()
                    if (next_line and 
                        not next_line.startswith("|") and 
                        not next_line.startswith("=") and
                        not next_line.startswith("-") and
                        next_line != ""):
                        break
                    i += 1
                continue
                
            elif line.strip() == "AutoGluon Inference Containers":
                self.logger.info(f"üìù Found AutoGluon Inference Containers section at line {i}")
                inference_section_found = True
                new_lines.append(line)
                new_lines.append("===============================")
                new_lines.append("") 
                new_lines.append("| Framework       | AutoGluon Version  | Job Type  | CPU/GPU | Python Version Options | Example URL                                                                                       |")
                new_lines.append("|-----------------|--------------------|-----------|---------|------------------------|---------------------------------------------------------------------------------------------------|")
                
                if 'gpu' in inference_images:
                    gpu_row = self.create_table_row_with_constructed_url(inference_images['gpu'], "inference", "GPU")
                    new_lines.append(gpu_row)
                if 'cpu' in inference_images:
                    cpu_row = self.create_table_row_with_constructed_url(inference_images['cpu'], "inference", "CPU")
                    new_lines.append(cpu_row)
                
                i += 1
                while i < len(lines):
                    next_line = lines[i].strip()
                    if (next_line and 
                        not next_line.startswith("|") and 
                        not next_line.startswith("=") and
                        not next_line.startswith("-") and
                        next_line != ""):
                        break
                    i += 1
                continue
                
            else:
                new_lines.append(line)
                i += 1
        
        if not training_section_found:
            self.logger.warning("‚ö†Ô∏è AutoGluon Training Containers section not found!")
            self.logger.warning("Lines containing 'AutoGluon Training':")
            for i, line in enumerate(lines):
                if "AutoGluon Training" in line:
                    self.logger.warning(f"  Line {i}: '{line.strip()}'")
                    
        if not inference_section_found:
            self.logger.warning("‚ö†Ô∏è AutoGluon Inference Containers section not found!")
            self.logger.warning("Lines containing 'AutoGluon Inference':")
            for i, line in enumerate(lines):
                if "AutoGluon Inference" in line:
                    self.logger.warning(f"  Line {i}: '{line.strip()}'")
            
        self.logger.info(f"‚úÖ Main sections updated with constructed URLs. Lines: {len(lines)} -> {len(new_lines)}")
        return '\n'.join(new_lines)
    
    def create_table_row_with_constructed_url(self, image_info: Dict, job_type: str, compute_type: str) -> str:
        """Create a table row using the constructed image URL"""
        python_version = self.convert_python_version(image_info['python_versions'][0])
        constructed_url = image_info['image_uri']
        
        self.logger.info(f"üìã Creating {job_type} {compute_type} row with constructed URL: {constructed_url}")
        
        return f"| AutoGluon {self.current_version} | {self.current_version}              | {job_type} | {compute_type}     | {python_version} ({image_info['python_versions'][0]})             | {constructed_url} |"
    
    def create_table_row_with_actual_uri(self, image_info: Dict, job_type: str, compute_type: str) -> str:
        """Create a table row using the actual image URI extracted from repository"""
        python_version = self.convert_python_version(image_info['python_versions'][0])
        actual_uri = image_info['image_uri']
        
        self.logger.info(f"üìã Creating {job_type} {compute_type} row with actual URI: {actual_uri}")
        
        return f"| AutoGluon {self.current_version} | {self.current_version}              | {job_type} | {compute_type}     | {python_version} ({image_info['python_versions'][0]})             | {actual_uri} |"
    
    def extract_current_section(self, lines: list[str], section_name: str) -> list[str]:
        """Extract a current AutoGluon section from the markdown"""
        section_lines = []
        i = 0
        found_section = False
        
        while i < len(lines):
            line = lines[i]
            if section_name in line and "Prior" not in line:
                found_section = True
                prior_header = section_name.replace("AutoGluon", "Prior AutoGluon")
                section_lines.append(prior_header)
                i += 1
                while i < len(lines):
                    next_line = lines[i]
                    if ((next_line.startswith("AutoGluon") and "Containers" in next_line and section_name not in next_line) or
                        next_line.startswith("Prior AutoGluon") or 
                        next_line.startswith("(--------") or
                        next_line.startswith("---")):
                        break
                    section_lines.append(next_line)
                    i += 1
                break
            i += 1
        
        if found_section:
            self.logger.info(f"‚úÖ Extracted {section_name} section with {len(section_lines)} lines")
        else:
            self.logger.warning(f"‚ö†Ô∏è Could not find {section_name} section")
        
        return section_lines if found_section else []
            
    def parse_image_tag(self, tag: str, require_cuda: bool = True) -> Optional[Dict]:
        """Parse image tag to extract os_version, python_versions, and cuda_version"""
        try:
            self.logger.info(f"üîç Parsing image tag: {tag}")
            os_match = re.search(r'ubuntu(\d+)\.(\d+)', tag)
            if os_match:
                os_version = f"ubuntu{os_match.group(1)}.{os_match.group(2)}"
                self.logger.info(f"   Found OS version: {os_version}")
            else:
                self.logger.error(f"‚ùå Could not extract OS version from tag: {tag}")
                return None
            python_match = re.search(r'-py(\d+)-', tag)
            if python_match:
                python_version = f"py{python_match.group(1)}"
                self.logger.info(f"   Found Python version: {python_version}")
            else:
                self.logger.error(f"‚ùå Could not extract Python version from tag: {tag}")
                return None
            cuda_match = re.search(r'cu(\d+)', tag)
            if cuda_match:
                cuda_version = f"cu{cuda_match.group(1)}"
                self.logger.info(f"   Found CUDA version: {cuda_version}")
            elif require_cuda:
                self.logger.warning(f"‚ö†Ô∏è No CUDA version found in tag: {tag} (skipping - likely CPU image)")
                return None
            else:
                cuda_version = ""
                self.logger.info(f"   No CUDA version (CPU image)")
            return {
                'os_version': os_version,
                'python_versions': [python_version],
                'cuda_version': cuda_version
            }
        except Exception as e:
            self.logger.error(f"‚ùå Failed to parse image tag {tag}: {e}")
            return None
            
    def get_next_release_number(self, yaml_file: Path) -> int:
        """Get the next release number from the YAML file"""
        try:
            with open(yaml_file, 'r') as f:
                content = yaml.safe_load(f)
            if 'release_images' not in content:
                return 1
            max_num = 0
            for key in content['release_images'].keys():
                if isinstance(key, int):
                    max_num = max(max_num, key)
            return max_num + 1
        except Exception as e:
            self.logger.error(f"‚ùå Failed to get next release number from {yaml_file}: {e}")
            return 18 
            
    def backup_yaml_files(self):
        """Backup original YAML file contents"""
        try:
            with open(self.training_file, 'r') as f:
                self.original_training_content = f.read()
            with open(self.inference_file, 'r') as f:
                self.original_inference_content = f.read()
            self.logger.info("‚úÖ Original YAML files backed up")
        except Exception as e:
            self.logger.error(f"‚ùå Failed to backup YAML files: {e}")
            raise
            
    def backup_available_images_file(self):
        """Backup original available_images.md file content"""
        try:
            with open(self.available_images_file, 'r') as f:
                self.original_available_images_content = f.read()
            self.logger.info("‚úÖ Original available_images.md file backed up")
        except Exception as e:
            self.logger.error(f"‚ùå Failed to backup available_images.md: {e}")
            raise
            
    def revert_yaml_files(self):
        """Revert YAML files to original content"""
        try:
            if self.original_training_content:
                with open(self.training_file, 'w') as f:
                    f.write(self.original_training_content)
            if self.original_inference_content:
                with open(self.inference_file, 'w') as f:
                    f.write(self.original_inference_content)
            self.logger.info("‚úÖ YAML files reverted to original state")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to revert YAML files: {e}")
            return False
            
    def commit_and_push_yaml_changes(self, commit_message: str):
        """Commit and push YAML file changes to the branch"""
        try:
            original_dir = os.getcwd()
            os.chdir(self.repo_dir)
            
            self.run_subprocess_with_logging(['git', 'add', 'release_images_training.yml', 'release_images_inference.yml'], check=True)
            
            self.run_subprocess_with_logging(['git', 'commit', '-m', commit_message], check=True)
            
            # Use the instance variable
            self.run_subprocess_with_logging(['git', 'push', 'origin', self.branch_name], check=True)
            self.logger.info(f"‚úÖ YAML changes committed and pushed: {commit_message}")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to commit and push YAML changes: {e}")
            return False
        finally:
            os.chdir(original_dir)

            
    def commit_and_push_available_images_changes(self, commit_message: str):
        """Commit and push available_images.md changes to the branch"""
        try:
            original_dir = os.getcwd()
            os.chdir(self.repo_dir)
            
            # Add the modified available_images.md file
            self.run_subprocess_with_logging(['git', 'add', 'available_images.md'], check=True)
            
            # Commit changes
            self.run_subprocess_with_logging(['git', 'commit', '-m', commit_message], check=True)
            
            # Push changes
            branch_name = f"{self.current_version}-release"
            self.run_subprocess_with_logging(['git', 'push', 'origin', branch_name], check=True)
            self.logger.info(f"‚úÖ available_images.md changes committed and pushed: {commit_message}")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to commit and push available_images.md changes: {e}")
            return False
        finally:
            os.chdir(original_dir)
            
    def update_yaml_file(self, yaml_file: Path, image_info: Dict, file_type: str):
        """Update a single YAML file with AutoGluon configuration"""
        try:
            with open(yaml_file, 'r') as f:
                original_content = f.read()
            with open(yaml_file, 'r') as f:
                content = yaml.safe_load(f)
            if 'release_images' not in content:
                content['release_images'] = {}
            next_num = self.get_next_release_number(yaml_file)
            autogluon_section = f"""  {next_num}:
    framework: "autogluon"
    version: "{self.current_version}"
    arch_type: "x86"
    {file_type}:
      device_types: ["cpu", "gpu"]
      python_versions: ["{image_info['python_versions'][0]}"]
      os_version: "{image_info['os_version']}"
      cuda_version: "{image_info['cuda_version']}"
      example: False
      disable_sm_tag: False
      force_release: False"""
            if not original_content.startswith('---'):
                new_content = f"---\n{original_content.rstrip()}\n{autogluon_section}\n"
            else:
                new_content = f"{original_content.rstrip()}\n{autogluon_section}\n"
            with open(yaml_file, 'w') as f:
                f.write(new_content)
            self.logger.info(f"‚úÖ Updated {yaml_file.name} with AutoGluon config (release #{next_num})")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Failed to update {yaml_file}: {e}")
            return False
            
    def update_release_images_files(self, image_info: Dict):
        """Update both training and inference YAML files"""
        success = True
        if not self.update_yaml_file(self.training_file, image_info, 'training'):
            success = False
        if not self.update_yaml_file(self.inference_file, image_info, 'inference'):
            success = False
        return success
        
    def wait_for_pr_merge(self, pr_type: str):
        """Wait for PR to be merged"""
        print(f"üìã Waiting for {pr_type} PR to be merged...")
        while True:
            if self.prompt_user(f"Is the {pr_type} PR merged?"):
                print(f"‚úÖ {pr_type} PR confirmed as merged. Proceeding...")
                break
            else:
                print(f"‚è≥ Waiting for {pr_type} PR merge...")

def main():
    """Main function for AutoGluon Release Images Automation"""
    import argparse
    parser = argparse.ArgumentParser(description='AutoGluon Release Images Automation - Updates YAML files and available_images.md')
    parser.add_argument('--current-version', required=True, help='Current version (e.g., 1.3.2)')
    parser.add_argument('--previous-version', required=True, help='Previous version (e.g., 1.3.1)')
    parser.add_argument('--fork-url', required=True, help='Your fork URL')
    parser.add_argument('--yaml-only', action='store_true', help='Run only YAML file updates and PR creation (first step). Without this flag, runs revert + available_images.md update (second step).')
    
    args = parser.parse_args()
    logging.basicConfig(level=logging.INFO)
    
    if args.yaml_only:
        print("üöÄ AutoGluon YAML-Only Release Automation")
        print("üìã This will update YAML files and create PR")
        print(f"üìã Branch name: {args.current_version}-release")
    else:
        print("üöÄ AutoGluon Revert + Available Images Automation") 
        print("üìã This will revert YAML files, update available_images.md, and create combined PR")
        print(f"üìã Branch name: {args.current_version}-update")
        
    automation = AutoGluonReleaseImagesAutomation(
        args.current_version,
        args.previous_version,
        args.fork_url,
        yaml_only=args.yaml_only
    )
    success = automation.run_release_images_automation(yaml_only=args.yaml_only)
    exit(0 if success else 1)

if __name__ == "__main__":
    main()