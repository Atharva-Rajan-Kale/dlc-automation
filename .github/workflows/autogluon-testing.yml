# .github/workflows/autogluon-testing.yml
name: AutoGluon Testing Suite

on:
  workflow_dispatch:
    inputs:
      current_version:
        description: 'Current version (e.g., 1.4.0)'
        required: true
        type: string
      previous_version:
        description: 'Previous version (e.g., 1.3.0)'
        required: true
        type: string
      fork_url:
        description: 'Your fork URL'
        required: true
        type: string
      test_suite:
        description: 'Test suite to run'
        required: true
        type: choice
        options:
          - 'all'
          - 'pip-check'
          - 'autogluon-tests'
          - 'sagemaker-tests'
          - 'security-tests'
          - 'quick-checks'
        default: 'all'
      pr_number:
        description: 'PR number (for security tests)'
        required: false
        type: string

  pull_request:
    branches: [ main, master ]
    paths:
      - '**.py'
      - 'requirements*.txt'
      - '.github/workflows/**'

permissions:
  id-token: write   # Required for OIDC
  contents: read
  actions: read
  pull-requests: write

env:
  PYTHONPATH: ${{ github.workspace }}/src
  REGION: us-east-1
  CODEBUILD_REGION: us-west-2

jobs:
  setup-testing:
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.matrix.outputs.test-matrix }}
      should-run-pip: ${{ steps.determine.outputs.pip }}
      should-run-autogluon: ${{ steps.determine.outputs.autogluon }}
      should-run-sagemaker: ${{ steps.determine.outputs.sagemaker }}
      should-run-security: ${{ steps.determine.outputs.security }}
      should-run-quick: ${{ steps.determine.outputs.quick }}
    steps:
      - name: Determine tests to run
        id: determine
        run: |
          case "${{ inputs.test_suite }}" in
            "all")
              echo "pip=true" >> $GITHUB_OUTPUT
              echo "autogluon=true" >> $GITHUB_OUTPUT
              echo "sagemaker=true" >> $GITHUB_OUTPUT
              echo "security=true" >> $GITHUB_OUTPUT
              echo "quick=true" >> $GITHUB_OUTPUT
              ;;
            "pip-check")
              echo "pip=true" >> $GITHUB_OUTPUT
              echo "autogluon=false" >> $GITHUB_OUTPUT
              echo "sagemaker=false" >> $GITHUB_OUTPUT
              echo "security=false" >> $GITHUB_OUTPUT
              echo "quick=false" >> $GITHUB_OUTPUT
              ;;
            "autogluon-tests")
              echo "pip=false" >> $GITHUB_OUTPUT
              echo "autogluon=true" >> $GITHUB_OUTPUT
              echo "sagemaker=false" >> $GITHUB_OUTPUT
              echo "security=false" >> $GITHUB_OUTPUT
              echo "quick=false" >> $GITHUB_OUTPUT
              ;;
            "sagemaker-tests")
              echo "pip=false" >> $GITHUB_OUTPUT
              echo "autogluon=false" >> $GITHUB_OUTPUT
              echo "sagemaker=true" >> $GITHUB_OUTPUT
              echo "security=false" >> $GITHUB_OUTPUT
              echo "quick=false" >> $GITHUB_OUTPUT
              ;;
            "security-tests")
              echo "pip=false" >> $GITHUB_OUTPUT
              echo "autogluon=false" >> $GITHUB_OUTPUT
              echo "sagemaker=false" >> $GITHUB_OUTPUT
              echo "security=true" >> $GITHUB_OUTPUT
              echo "quick=false" >> $GITHUB_OUTPUT
              ;;
            "quick-checks")
              echo "pip=false" >> $GITHUB_OUTPUT
              echo "autogluon=false" >> $GITHUB_OUTPUT
              echo "sagemaker=false" >> $GITHUB_OUTPUT
              echo "security=false" >> $GITHUB_OUTPUT
              echo "quick=true" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Setup test matrix
        id: matrix
        run: |
          echo 'test-matrix=["pip-check", "autogluon-tests", "sagemaker-tests"]' >> $GITHUB_OUTPUT

  pip-check-agent:
    runs-on: ubuntu-latest
    needs: setup-testing
    if: needs.setup-testing.outputs.should-run-pip == 'true'
    timeout-minutes: 60
    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/dlc-automation-oidc-role
          aws-region: ${{ env.REGION }}

      - name: Submit Pip Check Batch Job
        run: |
          JOB_ID=$(aws batch submit-job \
            --job-name "pip-check-${{ github.run_number }}" \
            --job-queue "${{ secrets.BATCH_JOB_QUEUE }}" \
            --job-definition "${{ secrets.BATCH_TEST_JOB_DEFINITION }}" \
            --container-overrides 'environment=[{name=GITHUB_TOKEN,value=${{ secrets.TOKEN }}},{name=currentVersion,value=${{ inputs.current_version }}},{name=previousVersion,value=${{ inputs.previous_version }}},{name=forkUrl,value=${{ inputs.fork_url }}},{name=testType,value=pip-check}]' \
            --query 'jobId' --output text)
          
          while true; do
            STATUS=$(aws batch describe-jobs --jobs $JOB_ID --query 'jobs[0].status' --output text)
            if [ "$STATUS" = "SUCCEEDED" ]; then break; elif [ "$STATUS" = "FAILED" ]; then exit 1; fi
            sleep 30
          done
          echo "✅ Pip check completed: $JOB_ID"

      - name: Upload pip check results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pip-check-results-${{ inputs.current_version }}
          path: |
            automation_logs/pip_check*.log
            pip_check_results/
          retention-days: 7

  autogluon-tests:
    runs-on: ubuntu-latest
    needs: setup-testing
    if: needs.setup-testing.outputs.should-run-autogluon == 'true'
    timeout-minutes: 90
    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/dlc-automation-oidc-role
          aws-region: ${{ env.REGION }}

      - name: Submit AutoGluon Tests Batch Job
        run: |
          JOB_ID=$(aws batch submit-job \
            --job-name "autogluon-tests-${{ github.run_number }}" \
            --job-queue "${{ secrets.BATCH_JOB_QUEUE }}" \
            --job-definition "${{ secrets.BATCH_TEST_JOB_DEFINITION }}" \
            --container-overrides 'environment=[{name=GITHUB_TOKEN,value=${{ secrets.TOKEN }}},{name=currentVersion,value=${{ inputs.current_version }}},{name=previousVersion,value=${{ inputs.previous_version }}},{name=forkUrl,value=${{ inputs.fork_url }}},{name=testType,value=autogluon-tests}]' \
            --query 'jobId' --output text)
          
          while true; do
            STATUS=$(aws batch describe-jobs --jobs $JOB_ID --query 'jobs[0].status' --output text)
            if [ "$STATUS" = "SUCCEEDED" ]; then break; elif [ "$STATUS" = "FAILED" ]; then exit 1; fi
            sleep 30
          done
          echo "✅ AutoGluon tests completed: $JOB_ID"

      - name: Upload AutoGluon test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: autogluon-test-results-${{ inputs.current_version }}
          path: |
            automation_logs/autogluon*.log
            autogluon_test_results/
          retention-days: 7

  sagemaker-tests:
    runs-on: ubuntu-latest
    needs: setup-testing
    if: needs.setup-testing.outputs.should-run-sagemaker == 'true'
    timeout-minutes: 120
    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/autogluon-github-oidc-role
          aws-region: ${{ env.REGION }}

      - name: Submit SageMaker Tests Batch Job
        run: |
          JOB_ID=$(aws batch submit-job \
            --job-name "sagemaker-tests-${{ github.run_number }}" \
            --job-queue "${{ secrets.BATCH_JOB_QUEUE }}" \
            --job-definition "${{ secrets.BATCH_TEST_JOB_DEFINITION }}" \
            --container-overrides 'environment=[{name=GITHUB_TOKEN,value=${{ secrets.TOKEN }}},{name=currentVersion,value=${{ inputs.current_version }}},{name=previousVersion,value=${{ inputs.previous_version }}},{name=forkUrl,value=${{ inputs.fork_url }}},{name=testType,value=sagemaker-tests}]' \
            --query 'jobId' --output text)
          
          while true; do
            STATUS=$(aws batch describe-jobs --jobs $JOB_ID --query 'jobs[0].status' --output text)
            if [ "$STATUS" = "SUCCEEDED" ]; then break; elif [ "$STATUS" = "FAILED" ]; then exit 1; fi
            sleep 30
          done
          echo "✅ SageMaker tests completed: $JOB_ID"

      - name: Upload SageMaker test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sagemaker-test-results-${{ inputs.current_version }}
          path: |
            automation_logs/sagemaker*.log
            sagemaker_test_results/
          retention-days: 7

  security-tests:
    runs-on: ubuntu-latest
    needs: setup-testing
    if: needs.setup-testing.outputs.should-run-security == 'true'
    timeout-minutes: 90
    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/autogluon-github-oidc-role
          aws-region: ${{ env.REGION }}

      - name: Submit Security Tests Batch Job
        run: |
          JOB_ID=$(aws batch submit-job \
            --job-name "security-tests-${{ github.run_number }}" \
            --job-queue "${{ secrets.BATCH_JOB_QUEUE }}" \
            --job-definition "${{ secrets.BATCH_TEST_JOB_DEFINITION }}" \
            --container-overrides 'environment=[{name=GITHUB_TOKEN,value=${{ secrets.TOKEN }}},{name=currentVersion,value=${{ inputs.current_version }}},{name=previousVersion,value=${{ inputs.previous_version }}},{name=forkUrl,value=${{ inputs.fork_url }}},{name=testType,value=security-tests}]' \
            --query 'jobId' --output text)
          
          while true; do
            STATUS=$(aws batch describe-jobs --jobs $JOB_ID --query 'jobs[0].status' --output text)
            if [ "$STATUS" = "SUCCEEDED" ]; then break; elif [ "$STATUS" = "FAILED" ]; then exit 1; fi
            sleep 30
          done
          echo "✅ Security tests completed: $JOB_ID"

      - name: Upload security test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-test-results-${{ inputs.current_version }}
          path: |
            automation_logs/security*.log
            security_test_results/
          retention-days: 14

  quick-checks:
    runs-on: ubuntu-latest
    needs: setup-testing
    if: needs.setup-testing.outputs.should-run-quick == 'true'
    timeout-minutes: 30
    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/autogluon-github-oidc-role
          aws-region: ${{ env.REGION }}

      - name: Submit Quick Checks Batch Job
        run: |
          JOB_ID=$(aws batch submit-job \
            --job-name "quick-checks-${{ github.run_number }}" \
            --job-queue "${{ secrets.BATCH_JOB_QUEUE }}" \
            --job-definition "${{ secrets.BATCH_TEST_JOB_DEFINITION }}" \
            --container-overrides 'environment=[{name=GITHUB_TOKEN,value=${{ secrets.TOKEN }}},{name=currentVersion,value=${{ inputs.current_version }}},{name=previousVersion,value=${{ inputs.previous_version }}},{name=forkUrl,value=${{ inputs.fork_url }}},{name=testType,value=quick-checks}]' \
            --query 'jobId' --output text)
          
          while true; do
            STATUS=$(aws batch describe-jobs --jobs $JOB_ID --query 'jobs[0].status' --output text)
            if [ "$STATUS" = "SUCCEEDED" ]; then break; elif [ "$STATUS" = "FAILED" ]; then exit 1; fi
            sleep 30
          done
          echo "✅ Quick checks completed: $JOB_ID"

      - name: Upload quick check results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quick-check-results-${{ inputs.current_version }}
          path: |
            automation_logs/quick_check*.log
          retention-days: 7

  test-summary:
    runs-on: ubuntu-latest
    needs: [setup-testing, pip-check-agent, autogluon-tests, sagemaker-tests, security-tests, quick-checks]
    if: always()
    steps:
      - name: Generate test summary
        run: |
          echo "## 🧪 AutoGluon Testing Suite Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version:** ${{ inputs.current_version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test Suite:** ${{ inputs.test_suite }}" >> $GITHUB_STEP_SUMMARY
          echo "**Region:** ${{ env.REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "**CodeBuild Region:** ${{ env.CODEBUILD_REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "**Authentication:** OIDC" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check each job result
          if [ "${{ needs.pip-check-agent.result }}" == "success" ]; then
            echo "✅ **Pip Check Agent:** Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.pip-check-agent.result }}" == "failure" ]; then
            echo "❌ **Pip Check Agent:** Failed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.pip-check-agent.result }}" == "skipped" ]; then
            echo "⏭️ **Pip Check Agent:** Skipped" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.autogluon-tests.result }}" == "success" ]; then
            echo "✅ **AutoGluon Tests:** Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.autogluon-tests.result }}" == "failure" ]; then
            echo "❌ **AutoGluon Tests:** Failed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.autogluon-tests.result }}" == "skipped" ]; then
            echo "⏭️ **AutoGluon Tests:** Skipped" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.sagemaker-tests.result }}" == "success" ]; then
            echo "✅ **SageMaker Tests:** Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.sagemaker-tests.result }}" == "failure" ]; then
            echo "❌ **SageMaker Tests:** Failed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.sagemaker-tests.result }}" == "skipped" ]; then
            echo "⏭️ **SageMaker Tests:** Skipped" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.security-tests.result }}" == "success" ]; then
            echo "✅ **Security Tests:** Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.security-tests.result }}" == "failure" ]; then
            echo "❌ **Security Tests:** Failed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.security-tests.result }}" == "skipped" ]; then
            echo "⏭️ **Security Tests:** Skipped" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.quick-checks.result }}" == "success" ]; then
            echo "✅ **Quick Checks:** Passed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.quick-checks.result }}" == "failure" ]; then
            echo "❌ **Quick Checks:** Failed" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.quick-checks.result }}" == "skipped" ]; then
            echo "⏭️ **Quick Checks:** Skipped" >> $GITHUB_STEP_SUMMARY
          fi